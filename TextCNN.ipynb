{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>[국민청원 데이터 분류하기]</h1>\n",
    "\n",
    "<p>• 주목받을 만한 청원 분류하기</p>\n",
    "<p>• '주목 받는다'는 것은 주관적인 일이기 때문에 주관적 판단을 배제하기 위해 딥러닝을 도입 </p>\n",
    "<p>• 높은 청원 참여인원을 기록한 글들의 특징을 학습하여, 새로운 글이 입력되었을 때 청원 참여인원이 높은 글들과의 유사성을 계산하여 판단</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>[크롤링]</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleep 90seconds. Count:584640, Local Time:2021-10-1821:52:08, Data Length: 24\n",
      "Sleep 90seconds. Count:585360, Local Time:2021-10-1821:54:56, Data Length: 31\n",
      "Sleep 90seconds. Count:590760, Local Time:2021-10-1822:06:56, Data Length: 93\n",
      "Sleep 90seconds. Count:594240, Local Time:2021-10-1822:14:36, Data Length: 182\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time \n",
    "\n",
    "result = pd.DataFrame()\n",
    "for i in range(584274, 595226):\n",
    "    URL = \"http://www1.president.go.kr/petitions/\"+str(i)\n",
    "    \n",
    "    response = requests.get(URL)\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    title = soup.find('h3', class_ = 'petitionsView_title')\n",
    "    count = soup.find('span', class_ = 'counter')\n",
    "    \n",
    "    for content in soup.select('div.petitionsView_write > div.View_write'):\n",
    "        content \n",
    "        a = []\n",
    "        for tag in soup.select('ul.petitionsView_info_list > li'):\n",
    "            a.append(tag.contents[1])\n",
    "            \n",
    "        if len(a) != 0:\n",
    "            df1 = pd.DataFrame({'start' : [a[1]],\n",
    "                                'end' : [a[2]],\n",
    "                                'category' : [a[0]],\n",
    "                                'count' : [count.text],\n",
    "                                'title' : [title.text],\n",
    "                                'content' : [content.text.strip()[0: 13000]]\n",
    "                              \n",
    "                               })\n",
    "            result = pd.concat([result, df1])\n",
    "            result.index = np.arange(len(result))\n",
    "            \n",
    "        if i % 60 == 0:\n",
    "            print(\"Sleep 90seconds. Count:\"+ str(i)\n",
    "                +\", Local Time:\"\n",
    "                + time.strftime('%Y-%m-%d', time.localtime(time.time()))\n",
    "                +\"\"+ time.strftime('%X', time.localtime(time.time()))\n",
    "                +\", Data Length: \" + str(len(result)))\n",
    "            time.sleep(90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>[크롤링 데이터 확인]</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(241, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>기타</td>\n",
       "      <td>203</td>\n",
       "      <td>보험회사로부터 사기당한 피해자로써, 보험회사 사기죄로 의율할수있도록 청원합니다</td>\n",
       "      <td>보험회사도, 보험가입자에게 법령을 위반하여..고객을 기망,착오케 하여, 지급하지않은...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>정치개혁</td>\n",
       "      <td>2,433</td>\n",
       "      <td>현직 국회의원의 모든 선거 자료에 지난 국회 출석률을 표시하도록 해주세요.</td>\n",
       "      <td>긴 말 안 쓰겠습니다.\\n\\r\\n현직 국회의원의 모든 선거 자료에 \\r\\n지난 국회...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>안전/환경</td>\n",
       "      <td>171</td>\n",
       "      <td>인천시 송월재개발 빨리 진행되게 해주세요!!</td>\n",
       "      <td>인천시 중구 송월 주택 재개발구역에 살고 있는 주민입니다.\\n\\r\\n이 지역이 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>보건복지</td>\n",
       "      <td>4,671</td>\n",
       "      <td>외국인 국민건강과 의료보험 폐지청원</td>\n",
       "      <td>우리나라 자국민 우선시되야할 국민건강 및 의료보험입니다\\n\\r\\n그걸 외국인에게도 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>행정</td>\n",
       "      <td>324</td>\n",
       "      <td>세무사 먹여살리는 복잡한 세금계산!!! 각종 세금 계산은 나라에서 해주세요!!</td>\n",
       "      <td>태어나서 처음으로 양도세를 내게 된 사람입니다.\\r\\n집안 대대로 있던 땅이 있었는...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        start         end category  count  \\\n",
       "0  2020-01-28  2020-02-27       기타    203   \n",
       "1  2020-01-28  2020-02-27     정치개혁  2,433   \n",
       "2  2020-01-28  2020-02-27    안전/환경    171   \n",
       "3  2020-01-28  2020-02-27     보건복지  4,671   \n",
       "4  2020-01-28  2020-02-27       행정    324   \n",
       "\n",
       "                                         title  \\\n",
       "0  보험회사로부터 사기당한 피해자로써, 보험회사 사기죄로 의율할수있도록 청원합니다   \n",
       "1    현직 국회의원의 모든 선거 자료에 지난 국회 출석률을 표시하도록 해주세요.   \n",
       "2                     인천시 송월재개발 빨리 진행되게 해주세요!!   \n",
       "3                          외국인 국민건강과 의료보험 폐지청원   \n",
       "4  세무사 먹여살리는 복잡한 세금계산!!! 각종 세금 계산은 나라에서 해주세요!!   \n",
       "\n",
       "                                             content  \n",
       "0  보험회사도, 보험가입자에게 법령을 위반하여..고객을 기망,착오케 하여, 지급하지않은...  \n",
       "1  긴 말 안 쓰겠습니다.\\n\\r\\n현직 국회의원의 모든 선거 자료에 \\r\\n지난 국회...  \n",
       "2  인천시 중구 송월 주택 재개발구역에 살고 있는 주민입니다.\\n\\r\\n이 지역이 10...  \n",
       "3  우리나라 자국민 우선시되야할 국민건강 및 의료보험입니다\\n\\r\\n그걸 외국인에게도 ...  \n",
       "4  태어나서 처음으로 양도세를 내게 된 사람입니다.\\r\\n집안 대대로 있던 땅이 있었는...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(result.shape)\n",
    "\n",
    "df = result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>[크롤링 직후의 데이터]</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start                                              2020-01-28\n",
       "end                                                2020-02-27\n",
       "category                                                 정치개혁\n",
       "count                                                   2,433\n",
       "title               현직 국회의원의 모든 선거 자료에 지난 국회 출석률을 표시하도록 해주세요.\n",
       "content     긴 말 안 쓰겠습니다.\\n\\r\\n현직 국회의원의 모든 선거 자료에 \\r\\n지난 국회...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>[전처리]</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_white_space(text):\n",
    "    text = re.sub(r'[\\t\\r\\n\\f\\v]','',str(text))\n",
    "    return text\n",
    "def remove_special_char(text):\n",
    "    text = re.sub('[^ㄱ-ㅣ가-힣 0-9]+','',str(text))\n",
    "    return text\n",
    "df.title = df.title.apply(remove_white_space)\n",
    "df.title = df.title.apply(remove_special_char)\n",
    "\n",
    "df.content = df.content.apply(remove_white_space)\n",
    "df.content = df.content.apply(remove_special_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>[전처리되었는지 확인]</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'긴 말 안 쓰겠습니다현직 국회의원의 모든 선거 자료에 지난 국회 출석률을 표시하도록 의무화 해주세요'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1]['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>[토크나이징]</h2>\n",
    "<p>• 형태소 분석기 패키지인 Konlpy모듈 import</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "df['title_token'] = df.title.apply(okt.morphs)\n",
    "df['content_token'] = df.content.apply(okt.nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>[파생변수 생성]</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start            object\n",
      "end              object\n",
      "category         object\n",
      "count             int64\n",
      "title            object\n",
      "content          object\n",
      "title_token      object\n",
      "content_token    object\n",
      "token_final      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['token_final'] = df.title_token + df.content_token\n",
    "\n",
    "df['count'] = df['count'].replace({',' : ''}, regex = True).apply(lambda x : int(x))\n",
    "print(df.dtypes)\n",
    "df['label'] = df['count'].apply(lambda x: 'Yes' if x>=1000 else 'NO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>[분석에 필요한 token_final과 label만 추출하여 df_drop에 저장]</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop = df[['token_final','label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>[단어 임베딩을 위한 WordfVec import]</h3>\n",
    "<p>• WordVec은 단어의 의미와 유사도를 반영하여 단어를 벡터로 표현하는 방식</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=7535, vector_size=100, alpha=0.025)\n",
      "[('번', 0.9965199828147888), ('발생', 0.9920846223831177), ('명', 0.9903942346572876), ('신천지', 0.9889833927154541), ('동선', 0.9887596368789673), ('감염', 0.9877769947052002), ('격리', 0.9877591729164124), ('전국', 0.9869346618652344), ('몇번', 0.9852475523948669), ('점점', 0.9833980798721313)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "embedding_model = Word2Vec(df_drop['token_final'],\n",
    "                           sg = 1,\n",
    "                           vector_size = 100,\n",
    "                           window = 2,\n",
    "                           min_count = 1,\n",
    "                           workers = 4\n",
    "                           )\n",
    "print(embedding_model)\n",
    "\n",
    "model_result = embedding_model.wv.most_similar(\"코로나\")\n",
    "print(model_result) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>[임베딩 모델 저장 및 로드]</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('번', 0.9965199828147888), ('발생', 0.9920846223831177), ('명', 0.9903942346572876), ('신천지', 0.9889833927154541), ('동선', 0.9887596368789673), ('감염', 0.9877769947052002), ('격리', 0.9877591729164124), ('전국', 0.9869346618652344), ('몇번', 0.9852475523948669), ('점점', 0.9833980798721313)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "embedding_model.wv.save_word2vec_format('data\\petitions_tokens_w2v')\n",
    "\n",
    "loaded_model = KeyedVectors.load_word2vec_format\n",
    "(\"data\\petitions_tokens_w2v\")\n",
    "#model_result = loaded_model.most_similar(\"코로나\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>[데이터를 Train, Validation set으로 랜덤하게 분할후 분할결과 저장]</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "rng = RandomState()\n",
    "\n",
    "tr = df_drop.sample(frac = 0.8, random_state=rng)\n",
    "val = df_drop.loc[~df_drop.index.isin(tr.index)]\n",
    "\n",
    "tr.to_csv('data/train.csv', index=False, encoding='utf-8-sig')\n",
    "val.to_csv('data/validation.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>[Field 클래스 정의]</h3>\n",
    "<p>• 자연어 처리 라이브러리인 torchtext 임포트</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.legacy.data import Field\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('[\\[\\]\\']','',str(text))\n",
    "    text = text.split(',')\n",
    "    return text\n",
    "TEXT = Field(tokenize=tokenizer)\n",
    "LABEL = Field(sequential=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>[데이터 불러오기]</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ['자', ' 가격', ' 리자', ' 들', ' 도', ' 대학교', ' 시험', ' 을', ' 볼', ' 수', ' 있게', ' 해주세요', ' 현재', ' 수능', ' 시험', ' 안', ' 확', ' 진자', ' 반', ' 사람', ' 자가', ' 격리', ' 이로', ' 대학교', ' 시험', ' 볼', ' 수', ' 사람', ' 대학교', ' 시험', ' 보기', ' 위', ' 자격', ' 요건', ' 최저', ' 점수', ' 위해', ' 수능', ' 반', ' 확', ' 진자', ' 그', ' 사람', ' 최저', ' 점수', ' 대학교', ' 시험', ' 적성', ' 고사', ' 논술시험', ' 볼', ' 자격', ' 박탈', ' 대학교', ' 방법', ' 논술', ' 전형', ' 수능', ' 전형', ' 적성', ' 전형', ' 등', ' 수능시험', ' 뿐', ' 대학교', ' 시험', ' 자가', ' 격리', ' 응시', ' 수', ' 생각'] NO\n",
      "Validation: ['대한민국', ' 해병대', ' 독립', ' 청원', ' 해병대', ' 창', ' 현재', ' 대한민국', ' 국가', ' 안보', ' 지대', ' 공헌', ' 전공', ' 유신', ' 독재', ' 정권', ' 시절', ' 국군', ' 조직', ' 법', ' 제', ' 군', ' 임무', ' 조항', ' 육해공군', ' 군', ' 해병대', ' 삭제', ' 수모', ' 이후', ' 해병대', ' 위상', ' 날', ' 갈수록', ' 약화', ' 실제', ' 북한', ' 연평도', ' 도발', ' 사건', ' 해병대', ' 변', ' 장비', ' 제때', ' 조달', ' 못', ' 뿐', ' 합참', ' 제', ' 목소리', ' 내지', ' 등', ' 차별', ' 대우', ' 온', ' 것', ' 현실', ' 임', ' 심지어', ' 해병대', ' 지원', ' 복무', ' 뒤', ' 전역', ' 역자', ' 국군', ' 조직', ' 법', ' 육해공군', ' 군', ' 체제', ' 한계', ' 때문', ' 병적', ' 해군', ' 분류', ' 수', ' 대한민국', ' 국가', ' 안보', ' 해병대', ' 전력', ' 강화', ' 사기', ' 진작', ' 위', ' 해병대', ' 위상', ' 강화', ' 통해', ' 독립성', ' 확보', ' 것', ' 선결', ' 과제', ' 것임', ' 따라서', ' 유신독재', ' 정권', ' 이전', ' 우리', ' 국군', ' 본연', ' 모습', ' 해병대', ' 독립성', ' 실질', ' 군', ' 체제', ' 해병대', ' 사령관', ' 해병대', ' 지휘', ' 감독', ' 권한', ' 명시', ' 등', ' 제도', ' 장치', ' 마련'] NO\n"
     ]
    }
   ],
   "source": [
    "from torchtext.legacy.data import TabularDataset\n",
    "\n",
    "train, validation = TabularDataset.splits(\n",
    "    path = 'data/',\n",
    "    train = 'train.csv',\n",
    "    validation = 'validation.csv',\n",
    "    format = 'csv',\n",
    "    fields = [('text', TEXT),('label', LABEL)],\n",
    "    skip_header = True\n",
    ")\n",
    "\n",
    "print(\"Train:\", train[0].text, train[0].label)\n",
    "print(\"Validation:\", validation[0].text,validation[0].label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>[단어장 및 DataLoader 정의]</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 벡터의 개수와 차원:torch.Size([6919, 100])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext.legacy.data import BucketIterator\n",
    "\n",
    "vectors = Vectors(name=\"data/petitions_tokens_w2v\")\n",
    "\n",
    "TEXT.build_vocab(train,\n",
    "                 vectors = vectors,min_freq = 1,max_size = None)\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "vocab = TEXT.vocab\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_iter, validation_iter = BucketIterator.splits(\n",
    "    datasets = (train,validation),\n",
    "    batch_size = 8,\n",
    "    device = device,\n",
    "    sort = False\n",
    ")\n",
    "print('임베딩 벡터의 개수와 차원:{}'.format(TEXT.vocab.vectors.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>TextCNN 모델 설계</h2>\n",
    "<p>• 문장을 단어 기준으로 나누어 컴퓨터가 단어를 이해할 수 있도록 텍스트를 벡터 형태로 전환하는 임베딩 실시</p>\n",
    "<p>• TextCNN은 문장의 문맥적 의미를 파악하는 과정에서 정보를 집약해주기 때문에 연산이 빠르기때문에 사용</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TextCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_built, emb_dim, dim_channel, kernel_wins, num_class):\n",
    "        \n",
    "        super(TextCNN, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(len(vocab_built), emb_dim)\n",
    "        self.embed.weight.data.copy_(vocab_built.vectors)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, dim_channel, (w, emb_dim)) for w in kernel_wins])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc = nn.Linear(len(kernel_wins)*dim_channel, num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "            \n",
    "        emb_x = self.embed(x)\n",
    "        emb_x = emb_x.unsqueeze(1)\n",
    "            \n",
    "        con_x = [self.relu(conv(emb_x)) for conv in self.convs]\n",
    "            \n",
    "        pool_x = [F.max_pool1d(x.squeeze(-1), x.size()[2]) for x in con_x]\n",
    "        fc_x = torch.cat(pool_x, dim=1)\n",
    "        fc_x = fc_x.squeeze(-1)\n",
    "        fc_x = self.dropout(fc_x)\n",
    "        logit = self.fc(fc_x)\n",
    "            \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>[모델 학습 함수 정의]</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_itr, optimizer):\n",
    "    \n",
    "    model.train()\n",
    "    corrects, train_loss = 0.0,0\n",
    "    \n",
    "    for batch in train_itr:\n",
    "        \n",
    "        text, target = batch.text, batch.label\n",
    "        text = torch.transpose(text, 0, 1)\n",
    "        target.data.sub_(1)\n",
    "        text, target = text.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logit = model(text)\n",
    "        \n",
    "        loss = F.cross_entropy(logit, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        result = torch.max(logit,1)[1]\n",
    "        corrects += (result.view(target.size()).data == target.data).sum()\n",
    "    \n",
    "    train_loss /= len(train_itr.dataset)\n",
    "    accuracy = 100.0 * corrects / len(train_itr.dataset)\n",
    "    \n",
    "    return train_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>[모델 평가 함수 정의]</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate (model, device, itr):\n",
    "    \n",
    "    model.eval()\n",
    "    corrects, test_loss = 0.0,0\n",
    "    \n",
    "    for batch in itr:\n",
    "        \n",
    "        text = batch.text\n",
    "        target = batch.label\n",
    "        text = torch.transpose(text, 0, 1)\n",
    "        target.data.sub_(1)\n",
    "        text, target = text.to(device), target.to(device)\n",
    "        \n",
    "        logit = model(text)\n",
    "        loss = F.cross_entropy(logit, target)\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "        result = torch.max(logit,1)[1]\n",
    "        corrects += (result.view(target.size()).data == target.data).sum()\n",
    "        \n",
    "    test_loss /= len(itr.dataset)\n",
    "    accuracy = 100.0 * corrects / len(itr.dataset)\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>[모델 학습 및 성능 확인]</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextCNN(\n",
      "  (embed): Embedding(6919, 100)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(1, 10, kernel_size=(3, 100), stride=(1, 1))\n",
      "    (1): Conv2d(1, 10, kernel_size=(4, 100), stride=(1, 1))\n",
      "    (2): Conv2d(1, 10, kernel_size=(5, 100), stride=(1, 1))\n",
      "  )\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (fc): Linear(in_features=30, out_features=2, bias=True)\n",
      ")\n",
      "Train Epoch: 1 \t Loss: 0.08566091159464782 \t Accuracy: 63.73057174682617%\n",
      "Valid Epoch: 1 \t Loss: 0.08140913024544716 \t Accuracy: 64.58333587646484%\n",
      "model saves at 64.58333587646484 accuracy\n",
      "-------------------------------------------------------------------------------\n",
      "Train Epoch: 2 \t Loss: 0.08439010196399195 \t Accuracy: 63.73057174682617%\n",
      "Valid Epoch: 2 \t Loss: 0.08189112320542336 \t Accuracy: 64.58333587646484%\n",
      "-------------------------------------------------------------------------------\n",
      "Train Epoch: 3 \t Loss: 0.08169856435894349 \t Accuracy: 63.73057174682617%\n",
      "Valid Epoch: 3 \t Loss: 0.08216600120067596 \t Accuracy: 64.58333587646484%\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = TextCNN(vocab, 100, 10,[3,4,5],2).to(device)\n",
    "print(model)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "best_test_acc = -1\n",
    "\n",
    "for epoch in range(1,3+1):\n",
    "    \n",
    "    tr_loss, tr_acc = train(model, device, train_iter, optimizer) \n",
    "    \n",
    "    print('Train Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, tr_loss, tr_acc))\n",
    "    \n",
    "    val_loss, val_acc = evaluate(model, device, validation_iter)\n",
    "    \n",
    "    print('Valid Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, val_loss, val_acc))\n",
    "    \n",
    "    if val_acc > best_test_acc:\n",
    "        best_test_acc = val_acc\n",
    "        \n",
    "        print(\"model saves at {} accuracy\".format(best_test_acc))\n",
    "        torch.save(model.state_dict(), \"TextCNN_Best_Validation\")\n",
    "    \n",
    "    print('-------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
